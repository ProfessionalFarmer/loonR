% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FeatureSelection.R
\name{feature.selection.RFE}
\alias{feature.selection.RFE}
\title{Recursive feature elimnation}
\usage{
feature.selection.RFE(
  feature.df,
  group,
  functions = "lrFuncs",
  seed = 111,
  scale = TRUE,
  sizes = c(1:5),
  repeats = 5,
  number = 5,
  method = "cv",
  cores = 50
)
}
\arguments{
\item{feature.df}{Row is sample, column is feature}

\item{functions}{Default: lrFuncs. lrFuncs, rfFuncs http://topepo.github.io/caret/available-models.html  There are a number of pre-defined sets of functions for several models, including: linear regression (in the object lmFuncs), random forests (rfFuncs), naive Bayes (nbFuncs), bagged trees (treebagFuncs) and functions that can be used with caretâ€™s train function (caretFuncs).}

\item{seed}{Default 111}

\item{scale}{Deafult TRUE}

\item{sizes}{Default c(1:5), The sizes determines the number of most important features the rfe should iterate.}

\item{repeats}{For repeated k-fold cross-validation only: the number of complete sets of folds to compute}

\item{number}{Either the number of folds or number of resampling iterations}

\item{method}{The external resampling method: boot, repeatedcv, cv, LOOCV or LGOCV (for repeated training/test splits)}

\item{cores}{cores for parallel}
}
\value{

}
\description{
Recursive feature elimnation
}
\examples{
loonR::feature.selection.RFE(miR.df, group, functions="lrFuncs")

Recursive feature elimnation (rfe) offers a rigorous way to determine the important variables before you even feed them into a ML algo.

}
